# 静静678的学习笔记
# A
## 安装
### 安装pytorch：
    pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html
### 安装tensorboard
    pip install pytorch-transformers tensorboardX
# B
# C
## conda
### 获取版本号/帮助
    获取版本号		        conda -V
    获取帮助	            conda -h
    获取环境相关命令的帮助	 conda env -h
### 环境相关
    创建环境	conda create -n environment_name
    创建指定python版本下包含某些包的环境	conda create -n environment_name python=3.7 numpy scipy
    进入环境	conda activate environment_name
    退出环境	conda deactivate
    删除环境	conda remove -n yourname --all
    列出环境	conda env list / conda info -e
    复制环境	conda create --name new_env_name --clone old_env_name
    指定目录下生成环境yml文件	 conda env export > 目录/environment.yml
    从yml文件创建环境	        conda env create -n env_name -f environment.yml
### 管理包
    对包的管理是在某个环境下进行的，先进入特定环境再进行包的操作比较好，不会出现把本该安装在A环境中的包安装在了B环境中这种情况。
    安装包	conda instal package_name
    查看当前环境包列表	conda list
    查看指定环境包列表	conda list -n environment_name
    查看conda源中包的信息	conda search package_name
    更新包	conda update package_name
    删除包	conda remove package_name
    清理无用的安装包	conda clean -p
    清理tar包	conda clean -t
    清理所有安装包及cache	conda clean -y --all
    更新anaconda	conda update annaconda
    最后三个清理命令类似于清理手机上的安装包、缓存，不会删除某个库，只是删除已经安装完成的那些安装包。
### 更换源
    1. 更换清华源
    windows:
    命令行中直接使用以下命令
    conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
    conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge 
    conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/
    设置搜索时显示通道地址
    conda config --set show_channel_urls yes
    linux:
    将以上配置文件写在~/.condarc中 vim ~/.condarc
    2. 更换中科大源
    conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/
    conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/
    conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/
    conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/msys2/
    conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/bioconda/
    conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/menpo/ 
    conda config --set show_channel_urls yes
    3. 显示现有安装源
    conda config --show channels
    4. 恢复默认源
    conda config --remove-key channels
    5. 移除某个源
    conda config --remove channels https://mirrors.cloud.tencent.com/anaconda/pkgs/pro/
## csv2xml
    from xml.etree.ElementTree import Element, ElementTree, SubElement
    import csv
    import os


    def csv_to_xml(file_name):
        with open(file_name, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            header = next(reader)

            root = Element("sentences")
            d = {
                '1': 'positive',
                '0': 'neutral',
                '-1': 'negative',
                '-2': 'NULL'
            }

            for row in reader:
                # for index, column in enumerate(row):
                node_sentence = Element('sentence')
                root.append(node_sentence)
                node_text = SubElement(node_sentence, 'text')
                # 给叶子节点text设置一个文本节点，用于显示文本内容
                node_text.text = row[1]
                node_aspectCategories = Element("aspectCategories")
                node_sentence.append(node_aspectCategories)
                node_aspectCategory = Element("aspectCategory", {'category': 'Location#Transportation', 'polarity': d[row[3]]})
                node_aspectCategories.append(node_aspectCategory)
                node_aspectCategory = Element("aspectCategory", {'category': 'Location#Downtown', 'polarity': d[row[4]]})
                node_aspectCategories.append(node_aspectCategory)
                node_aspectCategory = Element("aspectCategory", {'category': 'Location#Easy_to_find', 'polarity': d[row[5]]})
                node_aspectCategories.append(node_aspectCategory)
                node_aspectCategory = Element("aspectCategory", {'category': 'Service#Queue', 'polarity': d[row[6]]})
                node_aspectCategories.append(node_aspectCategory)
                node_aspectCategory = Element("aspectCategory", {'category': 'Service#Hospitality', 'polarity': d[row[7]]})
                node_aspectCategories.append(node_aspectCategory)
                node_aspectCategory = Element("aspectCategory", {'category': 'Service#Parking', 'polarity': d[row[8]]})
                node_aspectCategories.append(node_aspectCategory)
                node_aspectCategory = Element("aspectCategory", {'category': 'Service#Timely', 'polarity': d[row[9]]})
                node_aspectCategories.append(node_aspectCategory)
                node_aspectCategory = Element("aspectCategory", {'category': 'Price#Level', 'polarity': d[row[10]]})
                node_aspectCategories.append(node_aspectCategory)
                node_aspectCategory = Element("aspectCategory", {'category': 'Price#Cost_effective', 'polarity': d[row[11]]})
                node_aspectCategories.append(node_aspectCategory)
                node_aspectCategory = Element("aspectCategory", {'category': 'Price#Discount', 'polarity': d[row[12]]})
                node_aspectCategories.append(node_aspectCategory)
                node_aspectCategory = Element("aspectCategory", {'category': 'Ambience#Decoration', 'polarity': d[row[13]]})
                node_aspectCategories.append(node_aspectCategory)
                node_aspectCategory = Element("aspectCategory", {'category': 'Ambience#Noise', 'polarity': d[row[14]]})
                node_aspectCategories.append(node_aspectCategory)
                node_aspectCategory = Element("aspectCategory", {'category': 'Ambience#Space', 'polarity': d[row[15]]})
                node_aspectCategories.append(node_aspectCategory)
                node_aspectCategory = Element("aspectCategory", {'category': 'Ambience#Sanitary', 'polarity': d[row[16]]})
                node_aspectCategories.append(node_aspectCategory)
                node_aspectCategory = Element("aspectCategory", {'category': 'Food#Portion', 'polarity': d[row[17]]})
                node_aspectCategories.append(node_aspectCategory)
                node_aspectCategory = Element("aspectCategory", {'category': 'Food#Taste', 'polarity': d[row[18]]})
                node_aspectCategories.append(node_aspectCategory)
                node_aspectCategory = Element("aspectCategory", {'category': 'Food#Appearance', 'polarity': d[row[19]]})
                node_aspectCategories.append(node_aspectCategory)
                node_aspectCategory = Element("aspectCategory", {'category': 'Food#Recommend', 'polarity': d[row[20]]})
                node_aspectCategories.append(node_aspectCategory)
        beatau(root)
        return ElementTree(root)


    def beatau(e, level=0):
        if len(e) > 0:
            e.text = '\n' + '\t' * (level + 1)
            for child in e:
                beatau(child, level + 1)
            child.tail = child.tail[:-1]
        e.tail = '\n' + '  ' * level

        # 开始写xml文档
        # with open(path, "w", encoding="utf-8") as f:
        #     # writexml()第一个参数是目标文件对象，第二个参数是根节点的缩进格式，第三个参数是其他子节点的缩进格式，
        #     # 第四个参数制定了换行格式，第五个参数制定了xml内容的编码。
        #     doc.writexml(f, indent='', addindent='\t', newl='\n', encoding="utf-8")


    if __name__ == '__main__':
        base_path = os.path.join('xml_file')
        if not os.path.exists(base_path):
            os.mkdir(base_path)

        raw_train_path = os.path.join(base_path, 'raw/train.xml')
        raw_val_path = os.path.join(base_path, 'raw/val.xml')
        raw_test_path = os.path.join(base_path, 'raw/test.xml')

        raw_train_sample_path = os.path.join(base_path, 'raw/train_sample.xml')
        raw_val_sample_path = os.path.join(base_path, 'raw/val_sample.xml')
        raw_test_sample_path = os.path.join(base_path, 'raw/test_sample.xml')


        train = '/home/jye/ASAP/data/train.csv'
        ET = csv_to_xml(train)
        ET.write(raw_train_path, encoding='utf-8')

        val = '/home/jye/ASAP/data/dev.csv'
        ET = csv_to_xml(val)
        ET.write(raw_val_path, encoding='utf-8')

        test = '/home/jye/ASAP/data/test.csv'
        ET = csv_to_xml(test)
        ET.write(raw_test_path, encoding='utf-8')

        train_sample = '/home/jye/ASAP/data/train_sample.csv'
        ET = csv_to_xml(train_sample)
        ET.write(raw_train_sample_path, encoding='utf-8')

        val_sample = '/home/jye/ASAP/data/dev_sample.csv'
        ET = csv_to_xml(val_sample)
        ET.write(raw_val_sample_path, encoding='utf-8')

        test_sample = '/home/jye/ASAP/data/test_sample.csv'
        ET = csv_to_xml(test_sample)
        ET.write(raw_test_sample_path, encoding='utf-8')

# D
## Debug
### Load BERT
    我想load一个自己pretrain的bert，在load的时候出现参数的命名问题，只要不严格load就好了，忽略那部分参数（strict=False） 
    https://blog.csdn.net/qq_40420192/article/details/116460475?spm=1001.2101.3001.6650.3&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-3.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-3.pc_relevant_default&utm_relevant_index=6 
    用torch load参数的时候，因为文件名是str格式，直接load是load不进来的，要用torch.load() 
    self.model.load_state_dict(torch.load("/home/disk2/jye/SCAPT/results/Amazon/BERT_0417082222/epoch_7_step_125000.pt"),strict=False)
### TypeError: 'Tensor' object is not callable

# E
# F
## 服务器联网
    export ALL_PROXY=socks5://10.1.17.175:7890; export http_proxy=http://10.1.17.175:7890; export https_proxy=http://10.1.17.175:7890
# G
# H
# I
# J
# K
## kodcloud

# L 
## linux常用指令
    1. nvidia-smi
    2. nvidia-smi-L             查看显卡类型
    3. watch -n 3 nvidia-smi    刷新（动态）查看gpu
    4. gpustat -i               同上
    5. watch --color -n1 gpustat -cpu
    6. ps -ef | grep python     查看当前进程
    7. df -h                    查看硬盘情况
    8. du -h --max-depth=1      查看当前目录，哪个文件占用最大
    9. du -sh *                 看哪个目录占用空间大
    10. ps -axu | grep jingy | grep python | wc -l  查看线程数量
    11. cat /proc/cpuinfo | grep processor | wc -l  查看CPU线程总数
    12. cat /proc/cpuinfo                           查看CPU信息
    13. source ~/.bashrc 
    14. netstat -nultp 终端查看   
    15. df -m                   查看系统硬盘内存情况（以Mb为单位）
    16. mv -v <源文件地址> <目的文件地址>   用于移动文件位置
    17. rm -rf 目录名字   用于删除文件夹  (删除了就再找不回来了)
## Loss
### CE loss
#### 设置不同的class weight 和 sample weight

        batch_size = 10
        nb_classes = 2

        model = nn.Linear(10, nb_classes)
        weight = torch.empty(nb_classes).uniform_(0, 1)
        # 初始化CrossEntropy函数时传入各个class的权重, 
        # 且设置reduction为None表示不进行聚合，返回一个loss数组
        criterion = nn.CrossEntropyLoss(weight=weight, reduction='none')

        # This would be returned from your DataLoader
        x = torch.randn(batch_size, 10)
        target = torch.empty(batch_size, dtype=torch.long).random_(nb_classes)
        sample_weight = torch.empty(batch_size).uniform_(0, 1)

        output = model(x)
        loss = criterion(output, target)
        # 各个样本乘以其权重，然后求均值
        loss = loss * sample_weight
        loss.mean().backward()

* [设置不同的class weight 和 sample weight](https://www.jianshu.com/p/8c8169d2204c)
### Triplet Loss
* [三元组损失介绍](https://blog.csdn.net/zenglaoshi/article/details/106928204)
* [三元组损失论文](https://arxiv.org/pdf/1503.03832.pdf)
* [三元组损失代码1](https://github.com/AbnerHqC/GaitSet/blob/master/model/network/triplet.py)
* [三元组损失代码2](https://github.com/Cysu/open-reid/blob/master/reid/loss/triplet.py)
* [triphard 实现代码](https://blog.csdn.net/qq_32523711/article/details/103826600)
* [三元组损失代码解读3](https://blog.csdn.net/mos1896/article/details/109401079?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161950900616780366552628%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=161950900616780366552628&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-4-109401079.first_rank_v2_pc_rank_v29&utm_term=%E4%B8%89%E5%85%83%E7%BB%84%E6%8D%9F%E5%A4%B1)
* [不使用hardTriplet的情况：n个样本，算出nxn的距离矩阵](https://github.com/taylover-pei/SSDG-CVPR2020/blob/master/loss/hard_triplet_loss.py)
       
        class TripletLoss(nn.Module):
            """Triplet loss with hard positive/negative mining.
            
            Reference:
                Hermans et al. In Defense of the Triplet Loss for Person Re-Identification. arXiv:1703.07737.
            
            Imported from `<https://github.com/Cysu/open-reid/blob/master/reid/loss/triplet.py>`_.
            
            Args:
                margin (float, optional): margin for triplet. Default is 0.3.
            """
            
            def __init__(self, margin=0.3,global_feat, labels):
                super(TripletLoss, self).__init__()
                self.margin = margin
                # https://pytorch.org/docs/1.2.0/nn.html?highlight=marginrankingloss#torch.nn.MarginRankingLoss
                # 计算两个张量之间的相似度，两张量之间的距离>margin，loss 为正，否则loss 为 0
                self.ranking_loss = nn.MarginRankingLoss(margin=margin)
        
            def forward(self, inputs, targets):
                """
                Args:
                    inputs (torch.Tensor): feature matrix with shape (batch_size, feat_dim).
                    targets (torch.LongTensor): ground truth labels with shape (num_classes).
                """
                n = inputs.size(0)	# batch_size
                
                # Compute pairwise distance, replace by the official when merged
                dist = torch.pow(inputs, 2).sum(dim=1, keepdim=True).expand(n, n)
                dist = dist + dist.t()
                dist.addmm_(1, -2, inputs, inputs.t())
                dist = dist.clamp(min=1e-12).sqrt()  # for numerical stability
                
                # For each anchor, find the hardest positive and negative
                mask = targets.expand(n, n).eq(targets.expand(n, n).t())
                dist_ap, dist_an = [], []
                for i in range(n):
                    dist_ap.append(dist[i][mask[i]].max().unsqueeze(0))
                    dist_an.append(dist[i][mask[i] == 0].min().unsqueeze(0))
                dist_ap = torch.cat(dist_ap)
                dist_an = torch.cat(dist_an)
                
                # Compute ranking hinge loss
                y = torch.ones_like(dist_an)
                loss = self.ranking_loss(dist_an, dist_ap, y)
                return loss
# M
# N
# O
# P
## Pycharm搜索（文件、函数、内容）
    1. 文件内检索Ctrl + F
    2. 文件内替换Ctrl + R
    3. 项目中查找
    Ctrl + Shift + F
    该快捷键容易冲突，比如本地如果安装了搜狗输入法，可以先将对应的快捷键关闭再使用。
    Shift + Shift
    快捷键双击Shift，可以更精确的查找到类名/函数名/文件名
    勾选Include non-project items，可以搜索项目代码之外的内容，比如引入的库
    Classes搜索并跳转特定的类，快捷键Ctrl + N。
    Files可以快速跳转到文件，比如我输入c，就会检索出所有与C相关的文件，快捷键Ctrl + Shift + N
    另外Symbols的模糊查询也非常实用。当记不清完整的关键词时，可以进行模糊搜索。快捷键Ctrl + Alt + Shift + N
    4. 当前类、方法、属性列表
    快捷键Ctrl + F12， 可以把当前文件中的所有属性、类、方法都显示出来
    直接输入关键字，就可以检索出符合条件的属性/类/方法，并且可以定位到相关位置
    同样的功能，也可以通过Alt + 7 来实现，如下图所示。同样也是直接直接输入关键字进行搜索。
    5. 查看最近修改的文件
    快捷键ctrl + e。可以查看最近修改的文件
    6. 查看函数的调用关系
    当一个函数不知道被哪些地方调用的时候，可以通过快捷键Alt + F7 进行查看
## Pytorch load checkpoints出错
    RuntimeError: Attempting to deserialize object on CUDA device 4 but torch.cuda.device_count() is 4. Please use torch.load with map_location to map your storages to an existing device.
    解决：model = torch.load(model_path, map_location='cuda:0')
# Q
# R
## 软件学报参考文献格式zetora
[软件学报参考文献格式zetora](https://blog.csdn.net/still_night/article/details/104838490)
# S
# T
## transformers库
    tokenizer2 = RobertaTokenizer.from_pretrained("roberta-base") 
    inputs=tokenizer2('great food but the service was dreadful !', 'food',return_tensors="pt") 
    print(inputs) 
    {'input_ids': tensor([[    0, 12338,   689,    53,     5,   544,    21, 31715, 27785,     2,    2, 13193,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])} 
    tokenizer1 = BertTokenizer.from_pretrained("bert-base-uncased") 
    inputs=tokenizer1('great food but the service was dreadful !', 'food' return_tensors="pt") 
    {'input_ids': tensor([[  101,  2307,  2833,  2021,  1996,  2326,  2001, 21794,   102,  2833,
           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])} 
           
当输入两个句子的时候，会自动编码segment
### 关于使用Bert和Roberta的奇奇怪怪的结果
    from transformers import RobertaTokenizer, RobertaModel
    from transformers import BertTokenizer, BertModel
    import torch
    tokenizer = RobertaTokenizer.from_pretrained("roberta-base")
    tokenizer1 = BertTokenizer.from_pretrained("bert-base-uncased")
    roberta = RobertaModel.from_pretrained("roberta-base")
    bert = BertModel.from_pretrained('bert-base-uncased')
    inputs1=tokenizer('the staff should be a bit more friendly.','staff',return_tensors="pt")
    inputs2=tokenizer1('the staff should be a bit more friendly.','staff',return_tensors="pt")
    print(inputs1,'\n',inputs2)
    {'input_ids': tensor([[    0,   627,   813,   197,    28,    10,   828,    55,  5192,     4,
                2,     2, 17360,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])} 
    {'input_ids': tensor([[ 101, 1996, 3095, 2323, 2022, 1037, 2978, 2062, 5379, 1012,  102, 3095,
            102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}
    outputs1 = roberta(input_ids=inputs1['input_ids'])
    print(type(outputs1))
    <class 'transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions'>
    outputs1,_ = roberta(input_ids=inputs1['input_ids'])
    print(type(outputs1))
    <class 'str'>
    outputs2= bert(input_ids=inputs2['input_ids'])
    print(type(outputs2))
    <class 'transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions'>
    outputs2,_= bert(input_ids=inputs2['input_ids'])
    print(type(outputs2))
    <class 'str'>
    outputs2,_= bert(input_ids=inputs2['input_ids'],token_type_ids=inputs2['token_type_ids'])
    print(type(outputs2))
    <class 'str'>

## tmux
    tmux                        启动tmux
    exit 或 Ctrl+D              退出tmux
    tmux ls                     当前所有的tmux伪窗口
    tmux attach -t 0            重接会话，使用伪窗口编号
    tmux attach -t <name>       重接会话 使用伪窗口名称
    tmux kill-session -t 0      杀死会话
    tmux kill-session -t <name> 杀死会话
    tmux switch -t 0            切换会话
    tmux switch -t <session-name>
    tmux rename-session -t 0 <new-name>  重命名会话
    tmux list-keys              列出所有快捷键，及其对应的 Tmux 命令
    会话快捷键
    Ctrl+b d：                  分离当前会话。
    Ctrl+b s：                  列出所有会话。
    Ctrl+b $：                  重命名当前会话。
    窗格快捷键
    Ctrl+b %：                  划分左右两个窗格。
    Ctrl+b "：                  划分上下两个窗格。
    Ctrl+b <arrow key>：        光标切换到其他窗格。是指向要切换到的窗格的方向键，比如切换到下方窗格，就按方向键↓。
    Ctrl+b ;：                  光标切换到上一个窗格。
    Ctrl+b o：                  光标切换到下一个窗格。
    Ctrl+b {：                  当前窗格左移。
    Ctrl+b }：                  当前窗格右移。
    Ctrl+b Ctrl+o：             当前窗格上移。
    Ctrl+b Alt+o：              当前窗格下移。
    Ctrl+b x：                  关闭当前窗格。
    Ctrl+b !：                  将当前窗格拆分为一个独立窗口。
    Ctrl+b z：                  当前窗格全屏显示，再使用一次会变回原来大小。
    Ctrl+b Ctrl+<arrow key>：   按箭头方向调整窗格大小。
    Ctrl+b q：                  显示窗格编号
## tensorboardx
* 安装：pip install tensorboardX
* [使用方法参考](https://blog.csdn.net/bigbennyguo/article/details/87956434)
* [访问远程服务器上的tensorboard方法（成功）](https://www.cnblogs.com/monologuesmw/p/14465117.html)
* [访问远程服务器上的tensorboard方法（成功）](https://blog.csdn.net/power_kaikaige/article/details/125111527?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-0-125111527-blog-104371497.pc_relevant_aa&spm=1001.2101.3001.4242.1&utm_relevant_index=3)
* [稳定成功](https://blog.csdn.net/weixin_35653315/article/details/71327740)

        1 . 连接ssh时，将服务器的6006端口重定向到自己机器上来：

        ssh -L 16006:127.0.0.1:6006 jye@103.242.173.103
        ssh -L 16006:127.0.0.1:6006 jye@172.18.31.58
        ssh -L 16006:127.0.0.1:6006 jye@172.18.31.54

        其中：16006:127.0.0.1代表自己机器上的16006号端口，6006是服务器上tensorboard使用的端口。

        2 . 在服务器上使用6006端口正常启动tensorboard：

        tensorboard --logdir=runs --port=6006

        3 . 在本地浏览器中输入地址：
        
        127.0.0.1:16006

xshell隧道+在服务器上跳转至相应的目录下，输入命令tensorboard --logdir=<文件名称>  

## 画图
### t-SNE 
* [t-sne](https://zhuanlan.zhihu.com/p/358195652)

        import numpy as np
        import matplotlib.pyplot as plt
        import json
        from sklearn import manifold

        def draw_tsne(emb_filename):
            model = json.load(open(emb_filename, 'r'))
            X = np.array(model['features'])
            y = np.array(model['label'])
            '''t-SNE'''
            tsne = manifold.TSNE(n_components=2, init='pca', random_state=501)
            X_tsne = tsne.fit_transform(X)
            print(X.shape)
            print(X_tsne.shape)
            print(y.shape)
            print("Org data dimension is {}.Embedded data dimension is {}".format(X.shape[-1], X_tsne.shape[-1]))

            '''visualize'''
            x_min, x_max = X_tsne.min(0), X_tsne.max(0)
            X_norm = (X_tsne - x_min) / (x_max - x_min)  # 归一化

            plt.figure(figsize=(8, 8))
            for i in range(X_norm.shape[0]):
                plt.text(X_norm[i, 0], X_norm[i, 1], str(y[i]), color=plt.cm.Set1(y[i]),
                        fontdict={'weight': 'bold', 'size': 10})
            plt.xticks([])
            plt.yticks([])
            plt.suptitle('Roberta-SPC CE', fontsize=24)
            plt.show()


        emb_filename = ("/home/disk2/jye/ABSA_Curriculum_Learning/roberta-absa/roberta_spc_total_test1.json")
        draw_tsne(emb_filename)

### 训练过程图
    import matplotlib
    import matplotlib.pyplot as plt
    matplotlib.use('agg')

    def plot_jasons_lineplot(x, y, x_label, y_label, title, output_png_path):
        if x == None:
            x = range(1, len(y) + 1)

        _, ax = plt.subplots()
        plt.plot(x, y, linewidth=1)

        plt.xlabel(x_label)
        plt.ylabel(y_label)
        plt.title(title)

        plt.tight_layout()
        plt.savefig(output_png_path, dpi=400)
        plt.clf()

        print(f"plot saved at {output_png_path}")
# W
## word小技能：
 * ctrl+H 批量替换
# Y
## 亿图图示
[下载地址](pan.baidu.com/s/1iW9Jy9ljM04angzzkoyzQQ?pwd=1234 提取码: 1234)
#  *#*
## 梯子
    https://jinkela.bar/auth/register?code=WPP2
    https://foosber.com/auth/login
## 梯子auto脚本改写
    -
        name: auto_group
        type: url-test
        proxies:
        - 'Aperture 美国 | IPv6 直连 | NATIVE | V2'
        - 'Hinet 台湾 | IPv6 CDN | 宽频 | V1'
        - 'Metfone 柬埔寨 | IPv6 直连 | 0.5x | 宽频 | V1'
        - 'OCI 新加坡 | IPv6 直连 | NATIVE | V1'
        - 'PCCW 香港 | IPv6 直连 | 宽频 | V2'
        - 'Softbank 日本 | IPv6 直连 | 宽频 | V2'
        url: 'http://www.gstatic.com/generate_204'
        interval: '600'
    -
    
        name: 🔰国外流量
        type: select
        proxies:
        - 'auto_group'

## 后台并行（并行了但还没有完全并行）
        python -u CL_111.py --model_name bert_spc --curriculum_mode change_sample_weight --dataset restaurant --seed 8 --device cuda:9  &
        python -u CL.py --model_name bert_spc --curriculum_mode two_stage --dataset restaurant --seed 8 --device cuda:8  &
        python -u CL.py --model_name bert_spc --curriculum_mode gradual --dataset restaurant --seed 8 --device cuda:7  &
        python -u train.py --model_name bert_spc --train_mode CE+TL --dataset restaurant --seed 8 --device cuda:6   
        sleep  20m  

        python -u CL_111.py --seed 42 --dataset restaurant --device cuda:9  &
        python -u CL_111.py --seed 41 --dataset restaurant --device cuda:8  &
        python -u CL_111.py --seed 40 --dataset restaurant --device cuda:7 

        前台程序跑完了后才会执行sleep（目的是等后台的所有程序都跑完），然后回顺序执行下方的程序 